"""
ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì €.

ê¸°ì¡´ TTL íŒŒì¼ ë¡œë“œ ë° íŒŒì‹±, ìƒˆë¡œìš´ RDF ê·¸ëž˜í”„ì™€ ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ ë³‘í•©,
ì¤‘ë³µ ë°ì´í„° ê²€ì¶œ ë° ì²˜ë¦¬ ë¡œì§ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import shutil
from datetime import datetime
from typing import List, Dict, Optional, Any, Tuple, Set
from dataclasses import dataclass, field
from pathlib import Path

from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS, OWL, XSD
from rdflib.exceptions import ParserError
from rdflib.plugins.parsers.notation3 import BadSyntax

from integrated_models import FoodItem, NutritionInfo, ExerciseItem, FoodConsumption, ExerciseSession
from exceptions import DataValidationError, CalorieCalculationError


# ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ì •ì˜
DIET_NS = Namespace("http://example.org/diet#")
RDF_NS = RDF
RDFS_NS = RDFS
OWL_NS = OWL
XSD_NS = XSD


@dataclass
class ValidationResult:
    """TTL íŒŒì¼ ê²€ì¦ ê²°ê³¼."""
    is_valid: bool
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    triples_count: int = 0
    classes_count: int = 0
    properties_count: int = 0


@dataclass
class MergeResult:
    """ì˜¨í†¨ë¡œì§€ ë³‘í•© ê²°ê³¼."""
    success: bool
    merged_triples: int
    duplicate_triples: int
    new_triples: int
    backup_path: Optional[str] = None
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)


@dataclass
class Duplicate:
    """ì¤‘ë³µ ë°ì´í„° ì •ë³´."""
    subject: URIRef
    predicate: URIRef
    object: Any
    source_graph: str
    duplicate_type: str  # "exact", "similar", "conflict"


class OntologyManager:
    """
    ì˜¨í†¨ë¡œì§€ íŒŒì¼ ê´€ë¦¬ ë§¤ë‹ˆì €.
    
    ê¸°ì¡´ TTL íŒŒì¼ ë¡œë“œ ë° íŒŒì‹±, ìƒˆë¡œìš´ RDF ê·¸ëž˜í”„ì™€ ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ ë³‘í•©,
    ì¤‘ë³µ ë°ì´í„° ê²€ì¶œ ë° ì²˜ë¦¬ ë¡œì§ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, base_namespace: str = "http://example.org/diet#"):
        """
        OntologyManager ì´ˆê¸°í™”.
        
        Args:
            base_namespace: ê¸°ë³¸ ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ URI
        """
        self.base_namespace = Namespace(base_namespace)
        self.graph = Graph()
        
        # ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ë°”ì¸ë”©
        self.graph.bind("", self.base_namespace)
        self.graph.bind("rdf", RDF_NS)
        self.graph.bind("rdfs", RDFS_NS)
        self.graph.bind("owl", OWL_NS)
        self.graph.bind("xsd", XSD_NS)
        
        # í†µê³„ ì •ë³´
        self.stats = {
            "loaded_files": 0,
            "merged_graphs": 0,
            "created_backups": 0,
            "validation_checks": 0
        }
        
        print("âœ“ ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  - ê¸°ë³¸ ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤: {base_namespace}")
    
    def load_existing_ontology(self, file_path: str) -> Graph:
        """
        ê¸°ì¡´ TTL íŒŒì¼ì„ ë¡œë“œí•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            file_path: TTL íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Graph: ë¡œë“œëœ RDF ê·¸ëž˜í”„
            
        Raises:
            DataValidationError: íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ
        """
        if not os.path.exists(file_path):
            raise DataValidationError(f"ì˜¨í†¨ë¡œì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        try:
            graph = Graph()
            
            # ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ë°”ì¸ë”©
            graph.bind("", self.base_namespace)
            graph.bind("rdf", RDF_NS)
            graph.bind("rdfs", RDFS_NS)
            graph.bind("owl", OWL_NS)
            graph.bind("xsd", XSD_NS)
            
            # TTL íŒŒì¼ íŒŒì‹±
            graph.parse(file_path, format="turtle")
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["loaded_files"] += 1
            
            print(f"âœ“ ì˜¨í†¨ë¡œì§€ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {file_path}")
            print(f"  - íŠ¸ë¦¬í”Œ ìˆ˜: {len(graph)}")
            print(f"  - í´ëž˜ìŠ¤ ìˆ˜: {len(list(graph.subjects(RDF.type, OWL.Class)))}")
            print(f"  - ì†ì„± ìˆ˜: {len(list(graph.subjects(RDF.type, OWL.DatatypeProperty))) + len(list(graph.subjects(RDF.type, OWL.ObjectProperty)))}")
            
            return graph
            
        except (ParserError, BadSyntax) as e:
            raise DataValidationError(f"TTL íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            raise DataValidationError(f"ì˜¨í†¨ë¡œì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def merge_with_existing(self, new_graph: Graph, existing_path: str) -> MergeResult:
        """
        ìƒˆë¡œìš´ RDF ê·¸ëž˜í”„ë¥¼ ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ì™€ ë³‘í•©í•©ë‹ˆë‹¤.
        
        Args:
            new_graph: ë³‘í•©í•  ìƒˆë¡œìš´ ê·¸ëž˜í”„
            existing_path: ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            MergeResult: ë³‘í•© ê²°ê³¼
        """
        print(f"ðŸ“Š ì˜¨í†¨ë¡œì§€ ë³‘í•© ì‹œìž‘: {existing_path}")
        
        try:
            # ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ ë¡œë“œ
            existing_graph = self.load_existing_ontology(existing_path)
            
            # ë°±ì—… ìƒì„±
            backup_path = self.create_backup(existing_path)
            
            # ì¤‘ë³µ ê²€ì¶œ
            duplicates = self.detect_duplicates(new_graph, existing_graph)
            
            # ë³‘í•© ìˆ˜í–‰
            merged_graph = Graph()
            
            # ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ë°”ì¸ë”© ë³µì‚¬
            for prefix, namespace in existing_graph.namespaces():
                merged_graph.bind(prefix, namespace)
            
            # ê¸°ì¡´ ê·¸ëž˜í”„ì˜ ëª¨ë“  íŠ¸ë¦¬í”Œ ì¶”ê°€
            for triple in existing_graph:
                merged_graph.add(triple)
            
            # ìƒˆë¡œìš´ ê·¸ëž˜í”„ì—ì„œ ì¤‘ë³µë˜ì§€ ì•Šì€ íŠ¸ë¦¬í”Œë§Œ ì¶”ê°€
            new_triples = 0
            duplicate_triples = 0
            
            for triple in new_graph:
                if triple in existing_graph:
                    duplicate_triples += 1
                else:
                    merged_graph.add(triple)
                    new_triples += 1
            
            # ë³‘í•©ëœ ê·¸ëž˜í”„ë¥¼ ì›ë³¸ íŒŒì¼ì— ì €ìž¥
            self.save_ontology(merged_graph, existing_path)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["merged_graphs"] += 1
            
            result = MergeResult(
                success=True,
                merged_triples=len(merged_graph),
                duplicate_triples=duplicate_triples,
                new_triples=new_triples,
                backup_path=backup_path
            )
            
            print(f"âœ“ ì˜¨í†¨ë¡œì§€ ë³‘í•© ì™„ë£Œ:")
            print(f"  - ì´ íŠ¸ë¦¬í”Œ: {result.merged_triples}")
            print(f"  - ìƒˆë¡œìš´ íŠ¸ë¦¬í”Œ: {result.new_triples}")
            print(f"  - ì¤‘ë³µ íŠ¸ë¦¬í”Œ: {result.duplicate_triples}")
            print(f"  - ë°±ì—… íŒŒì¼: {backup_path}")
            
            return result
            
        except Exception as e:
            return MergeResult(
                success=False,
                merged_triples=0,
                duplicate_triples=0,
                new_triples=0,
                errors=[f"ë³‘í•© ì‹¤íŒ¨: {str(e)}"]
            )
    
    def detect_duplicates(self, graph1: Graph, graph2: Graph) -> List[Duplicate]:
        """
        ë‘ ê·¸ëž˜í”„ ê°„ì˜ ì¤‘ë³µ ë°ì´í„°ë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            graph1: ì²« ë²ˆì§¸ ê·¸ëž˜í”„
            graph2: ë‘ ë²ˆì§¸ ê·¸ëž˜í”„
            
        Returns:
            List[Duplicate]: ê²€ì¶œëœ ì¤‘ë³µ ë°ì´í„° ëª©ë¡
        """
        duplicates = []
        
        # ì •í™•í•œ ì¤‘ë³µ ê²€ì¶œ
        for triple in graph1:
            if triple in graph2:
                duplicates.append(Duplicate(
                    subject=triple[0],
                    predicate=triple[1],
                    object=triple[2],
                    source_graph="both",
                    duplicate_type="exact"
                ))
        
        # ìœ ì‚¬í•œ ì¤‘ë³µ ê²€ì¶œ (ê°™ì€ ì£¼ì–´ì™€ ìˆ ì–´ë¥¼ ê°€ì§€ì§€ë§Œ ë‹¤ë¥¸ ê°ì²´)
        subjects_predicates_1 = set((s, p) for s, p, o in graph1)
        subjects_predicates_2 = set((s, p) for s, p, o in graph2)
        
        common_sp = subjects_predicates_1.intersection(subjects_predicates_2)
        
        for s, p in common_sp:
            objects_1 = set(graph1.objects(s, p))
            objects_2 = set(graph2.objects(s, p))
            
            if objects_1 != objects_2:
                # ì¶©ëŒí•˜ëŠ” ê°’ë“¤
                for obj in objects_1.union(objects_2):
                    duplicates.append(Duplicate(
                        subject=s,
                        predicate=p,
                        object=obj,
                        source_graph="graph1" if obj in objects_1 else "graph2",
                        duplicate_type="conflict" if len(objects_1.intersection(objects_2)) == 0 else "similar"
                    ))
        
        print(f"ðŸ” ì¤‘ë³µ ê²€ì¶œ ì™„ë£Œ: {len(duplicates)}ê°œ ë°œê²¬")
        return duplicates
    
    def create_backup(self, file_path: str) -> str:
        """
        ì˜¨í†¨ë¡œì§€ íŒŒì¼ì˜ ë°±ì—…ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            file_path: ë°±ì—…í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: ìƒì„±ëœ ë°±ì—… íŒŒì¼ ê²½ë¡œ
            
        Raises:
            DataValidationError: ë°±ì—… ìƒì„± ì‹¤íŒ¨ ì‹œ
        """
        if not os.path.exists(file_path):
            raise DataValidationError(f"ë°±ì—…í•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        try:
            # ë°±ì—… íŒŒì¼ëª… ìƒì„± (íƒ€ìž„ìŠ¤íƒ¬í”„ í¬í•¨)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_path_obj = Path(file_path)
            backup_filename = f"{file_path_obj.stem}_backup_{timestamp}{file_path_obj.suffix}"
            backup_path = file_path_obj.parent / backup_filename
            
            # íŒŒì¼ ë³µì‚¬
            shutil.copy2(file_path, backup_path)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["created_backups"] += 1
            
            print(f"âœ“ ë°±ì—… íŒŒì¼ ìƒì„±: {backup_path}")
            return str(backup_path)
            
        except Exception as e:
            raise DataValidationError(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def save_ontology(self, graph: Graph, output_path: str) -> bool:
        """
        RDF ê·¸ëž˜í”„ë¥¼ TTL íŒŒì¼ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.
        
        Args:
            graph: ì €ìž¥í•  RDF ê·¸ëž˜í”„
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            bool: ì €ìž¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # TTL í˜•ì‹ìœ¼ë¡œ ì €ìž¥
            graph.serialize(destination=output_path, format="turtle")
            
            print(f"âœ“ ì˜¨í†¨ë¡œì§€ ì €ìž¥ ì™„ë£Œ: {output_path}")
            print(f"  - íŠ¸ë¦¬í”Œ ìˆ˜: {len(graph)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì˜¨í†¨ë¡œì§€ ì €ìž¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def validate_ttl_syntax(self, file_path: str) -> ValidationResult:
        """
        TTL íŒŒì¼ì˜ ë¬¸ë²•ì„ ê²€ì¦í•©ë‹ˆë‹¤.
        
        Args:
            file_path: ê²€ì¦í•  TTL íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ValidationResult: ê²€ì¦ ê²°ê³¼
        """
        print(f"ðŸ” TTL ë¬¸ë²• ê²€ì¦: {file_path}")
        
        result = ValidationResult(is_valid=False)
        
        if not os.path.exists(file_path):
            result.errors.append(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return result
        
        try:
            # ìž„ì‹œ ê·¸ëž˜í”„ë¡œ íŒŒì‹± ì‹œë„
            temp_graph = Graph()
            temp_graph.parse(file_path, format="turtle")
            
            # ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘
            result.triples_count = len(temp_graph)
            result.classes_count = len(list(temp_graph.subjects(RDF.type, OWL.Class)))
            result.properties_count = (
                len(list(temp_graph.subjects(RDF.type, OWL.DatatypeProperty))) +
                len(list(temp_graph.subjects(RDF.type, OWL.ObjectProperty)))
            )
            
            # ìŠ¤í‚¤ë§ˆ ê²€ì¦
            self._validate_schema(temp_graph, result)
            
            result.is_valid = len(result.errors) == 0
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["validation_checks"] += 1
            
            print(f"âœ“ TTL ê²€ì¦ ì™„ë£Œ:")
            print(f"  - ìœ íš¨ì„±: {'í†µê³¼' if result.is_valid else 'ì‹¤íŒ¨'}")
            print(f"  - íŠ¸ë¦¬í”Œ ìˆ˜: {result.triples_count}")
            print(f"  - í´ëž˜ìŠ¤ ìˆ˜: {result.classes_count}")
            print(f"  - ì†ì„± ìˆ˜: {result.properties_count}")
            print(f"  - ì˜¤ë¥˜ ìˆ˜: {len(result.errors)}")
            print(f"  - ê²½ê³  ìˆ˜: {len(result.warnings)}")
            
            return result
            
        except (ParserError, BadSyntax) as e:
            result.errors.append(f"TTL ë¬¸ë²• ì˜¤ë¥˜: {str(e)}")
            return result
        except Exception as e:
            result.errors.append(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return result
    
    def _validate_schema(self, graph: Graph, result: ValidationResult) -> None:
        """ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦."""
        # í´ëž˜ìŠ¤ ê²€ì¦
        for cls in graph.subjects(RDF.type, OWL.Class):
            # í´ëž˜ìŠ¤ì— ë¼ë²¨ì´ ìžˆëŠ”ì§€ í™•ì¸
            if not list(graph.objects(cls, RDFS.label)):
                result.warnings.append(f"í´ëž˜ìŠ¤ {cls}ì— ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤")
        
        # ì†ì„± ê²€ì¦
        for prop in graph.subjects(RDF.type, OWL.DatatypeProperty):
            # ë„ë©”ì¸ê³¼ ë²”ìœ„ í™•ì¸
            domains = list(graph.objects(prop, RDFS.domain))
            ranges = list(graph.objects(prop, RDFS.range))
            
            if not domains:
                result.warnings.append(f"ë°ì´í„° ì†ì„± {prop}ì— ë„ë©”ì¸ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            if not ranges:
                result.warnings.append(f"ë°ì´í„° ì†ì„± {prop}ì— ë²”ìœ„ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        for prop in graph.subjects(RDF.type, OWL.ObjectProperty):
            # ë„ë©”ì¸ê³¼ ë²”ìœ„ í™•ì¸
            domains = list(graph.objects(prop, RDFS.domain))
            ranges = list(graph.objects(prop, RDFS.range))
            
            if not domains:
                result.warnings.append(f"ê°ì²´ ì†ì„± {prop}ì— ë„ë©”ì¸ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            if not ranges:
                result.warnings.append(f"ê°ì²´ ì†ì„± {prop}ì— ë²”ìœ„ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    def extend_ontology_schema(self, graph: Graph) -> Graph:
        """
        ì˜¨í†¨ë¡œì§€ ìŠ¤í‚¤ë§ˆë¥¼ í™•ìž¥í•˜ì—¬ ìŒì‹/ìš´ë™ ê´€ë ¨ í´ëž˜ìŠ¤ì™€ ì†ì„±ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            graph: í™•ìž¥í•  ê·¸ëž˜í”„
            
        Returns:
            Graph: í™•ìž¥ëœ ê·¸ëž˜í”„
        """
        print("ðŸ”§ ì˜¨í†¨ë¡œì§€ ìŠ¤í‚¤ë§ˆ í™•ìž¥ ì¤‘...")
        
        # ìƒˆë¡œìš´ í´ëž˜ìŠ¤ ì •ì˜
        new_classes = [
            (self.base_namespace.NutritionInfo, "ì˜ì–‘ ì •ë³´"),
            (self.base_namespace.FoodConsumption, "ìŒì‹ ì„­ì·¨"),
            (self.base_namespace.ExerciseSession, "ìš´ë™ ì„¸ì…˜"),
            (self.base_namespace.User, "ì‚¬ìš©ìž")
        ]
        
        for cls_uri, label in new_classes:
            graph.add((cls_uri, RDF.type, OWL.Class))
            graph.add((cls_uri, RDFS.label, Literal(label, lang="ko")))
            graph.add((cls_uri, RDFS.subClassOf, self.base_namespace.DietConcept))
        
        # ìƒˆë¡œìš´ ë°ì´í„° ì†ì„± ì •ì˜
        new_data_properties = [
            # ì˜ì–‘ ì •ë³´ ì†ì„±
            (self.base_namespace.hasCaloriesPer100g, self.base_namespace.NutritionInfo, XSD.decimal, "100gë‹¹ ì¹¼ë¡œë¦¬"),
            (self.base_namespace.hasFiber, self.base_namespace.NutritionInfo, XSD.decimal, "ì‹ì´ì„¬ìœ (g)"),
            (self.base_namespace.hasSodium, self.base_namespace.NutritionInfo, XSD.decimal, "ë‚˜íŠ¸ë¥¨(mg)"),
            
            # ìŒì‹ ì„­ì·¨ ì†ì„±
            (self.base_namespace.consumedAmount, self.base_namespace.FoodConsumption, XSD.decimal, "ì„­ì·¨ëŸ‰(g)"),
            (self.base_namespace.consumedCalories, self.base_namespace.FoodConsumption, XSD.decimal, "ì„­ì·¨ ì¹¼ë¡œë¦¬"),
            (self.base_namespace.consumedAt, self.base_namespace.FoodConsumption, XSD.dateTime, "ì„­ì·¨ ì‹œê°„"),
            
            # ìš´ë™ ì„¸ì…˜ ì†ì„±
            (self.base_namespace.hasMET, self.base_namespace.Exercise, XSD.decimal, "MET ê°’"),
            (self.base_namespace.hasWeight, self.base_namespace.ExerciseSession, XSD.decimal, "ì²´ì¤‘(kg)"),
            (self.base_namespace.sessionDuration, self.base_namespace.ExerciseSession, XSD.decimal, "ì„¸ì…˜ ì‹œê°„(ë¶„)"),
            (self.base_namespace.caloriesBurned, self.base_namespace.ExerciseSession, XSD.decimal, "ì†Œëª¨ ì¹¼ë¡œë¦¬"),
            (self.base_namespace.performedAt, self.base_namespace.ExerciseSession, XSD.dateTime, "ìš´ë™ ì‹œê°„"),
            
            # ì‚¬ìš©ìž ì†ì„±
            (self.base_namespace.hasAge, self.base_namespace.User, XSD.integer, "ë‚˜ì´"),
            (self.base_namespace.hasHeight, self.base_namespace.User, XSD.decimal, "í‚¤(cm)"),
            (self.base_namespace.hasCurrentWeight, self.base_namespace.User, XSD.decimal, "í˜„ìž¬ ì²´ì¤‘(kg)")
        ]
        
        for prop_uri, domain, range_type, label in new_data_properties:
            graph.add((prop_uri, RDF.type, OWL.DatatypeProperty))
            graph.add((prop_uri, RDFS.domain, domain))
            graph.add((prop_uri, RDFS.range, range_type))
            graph.add((prop_uri, RDFS.label, Literal(label, lang="ko")))
        
        # ìƒˆë¡œìš´ ê°ì²´ ì†ì„± ì •ì˜
        new_object_properties = [
            (self.base_namespace.hasNutritionInfo, self.base_namespace.Food, self.base_namespace.NutritionInfo, "ì˜ì–‘ ì •ë³´ í¬í•¨"),
            (self.base_namespace.consumedFood, self.base_namespace.FoodConsumption, self.base_namespace.Food, "ì„­ì·¨í•œ ìŒì‹"),
            (self.base_namespace.performedExercise, self.base_namespace.ExerciseSession, self.base_namespace.Exercise, "ìˆ˜í–‰í•œ ìš´ë™"),
            (self.base_namespace.hasConsumption, self.base_namespace.User, self.base_namespace.FoodConsumption, "ìŒì‹ ì„­ì·¨ ê¸°ë¡"),
            (self.base_namespace.hasExerciseSession, self.base_namespace.User, self.base_namespace.ExerciseSession, "ìš´ë™ ì„¸ì…˜ ê¸°ë¡")
        ]
        
        for prop_uri, domain, range_type, label in new_object_properties:
            graph.add((prop_uri, RDF.type, OWL.ObjectProperty))
            graph.add((prop_uri, RDFS.domain, domain))
            graph.add((prop_uri, RDFS.range, range_type))
            graph.add((prop_uri, RDFS.label, Literal(label, lang="ko")))
        
        print(f"âœ“ ìŠ¤í‚¤ë§ˆ í™•ìž¥ ì™„ë£Œ:")
        print(f"  - ìƒˆë¡œìš´ í´ëž˜ìŠ¤: {len(new_classes)}ê°œ")
        print(f"  - ìƒˆë¡œìš´ ë°ì´í„° ì†ì„±: {len(new_data_properties)}ê°œ")
        print(f"  - ìƒˆë¡œìš´ ê°ì²´ ì†ì„±: {len(new_object_properties)}ê°œ")
        
        return graph
    
    def convert_food_to_rdf(self, food: FoodItem, nutrition: NutritionInfo) -> Graph:
        """
        ìŒì‹ ë°ì´í„°ë¥¼ RDF ê·¸ëž˜í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            food: ìŒì‹ ì•„ì´í…œ
            nutrition: ì˜ì–‘ ì •ë³´
            
        Returns:
            Graph: ë³€í™˜ëœ RDF ê·¸ëž˜í”„
        """
        graph = Graph()
        
        # ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ë°”ì¸ë”©
        graph.bind("", self.base_namespace)
        graph.bind("rdf", RDF_NS)
        graph.bind("rdfs", RDFS_NS)
        graph.bind("owl", OWL_NS)
        graph.bind("xsd", XSD_NS)
        
        # ìŒì‹ URI ìƒì„±
        food_uri = food.to_uri(self.base_namespace)
        nutrition_uri = URIRef(f"{food_uri}_nutrition")
        
        # ìŒì‹ ì¸ìŠ¤í„´ìŠ¤
        graph.add((food_uri, RDF.type, self.base_namespace.Food))
        graph.add((food_uri, RDFS.label, Literal(food.name, lang="ko")))
        
        if food.category:
            graph.add((food_uri, self.base_namespace.hasCategory, Literal(food.category)))
        if food.manufacturer:
            graph.add((food_uri, self.base_namespace.hasManufacturer, Literal(food.manufacturer)))
        
        # ì˜ì–‘ ì •ë³´ ì¸ìŠ¤í„´ìŠ¤
        graph.add((nutrition_uri, RDF.type, self.base_namespace.NutritionInfo))
        graph.add((nutrition_uri, self.base_namespace.hasCaloriesPer100g, Literal(nutrition.calories_per_100g)))
        graph.add((nutrition_uri, self.base_namespace.hasCarbohydrate, Literal(nutrition.carbohydrate)))
        graph.add((nutrition_uri, self.base_namespace.hasProtein, Literal(nutrition.protein)))
        graph.add((nutrition_uri, self.base_namespace.hasFat, Literal(nutrition.fat)))
        graph.add((nutrition_uri, self.base_namespace.hasFiber, Literal(nutrition.fiber)))
        graph.add((nutrition_uri, self.base_namespace.hasSodium, Literal(nutrition.sodium)))
        
        # ê´€ê³„ ì„¤ì •
        graph.add((food_uri, self.base_namespace.hasNutritionInfo, nutrition_uri))
        
        return graph
    
    def convert_exercise_to_rdf(self, exercise: ExerciseItem) -> Graph:
        """
        ìš´ë™ ë°ì´í„°ë¥¼ RDF ê·¸ëž˜í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            exercise: ìš´ë™ ì•„ì´í…œ
            
        Returns:
            Graph: ë³€í™˜ëœ RDF ê·¸ëž˜í”„
        """
        graph = Graph()
        
        # ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ë°”ì¸ë”©
        graph.bind("", self.base_namespace)
        graph.bind("rdf", RDF_NS)
        graph.bind("rdfs", RDFS_NS)
        graph.bind("owl", OWL_NS)
        graph.bind("xsd", XSD_NS)
        
        # ìš´ë™ URI ìƒì„±
        exercise_uri = exercise.to_uri(self.base_namespace)
        
        # ìš´ë™ ì¸ìŠ¤í„´ìŠ¤
        graph.add((exercise_uri, RDF.type, self.base_namespace.Exercise))
        graph.add((exercise_uri, RDFS.label, Literal(exercise.name, lang="ko")))
        graph.add((exercise_uri, self.base_namespace.hasMET, Literal(exercise.met_value)))
        
        if exercise.description:
            graph.add((exercise_uri, RDFS.comment, Literal(exercise.description, lang="ko")))
        if exercise.category:
            graph.add((exercise_uri, self.base_namespace.hasCategory, Literal(exercise.category)))
        
        return graph
    
    def convert_consumption_to_rdf(self, consumption: FoodConsumption) -> Graph:
        """
        ìŒì‹ ì„­ì·¨ ë°ì´í„°ë¥¼ RDF ê·¸ëž˜í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            consumption: ìŒì‹ ì„­ì·¨ ê¸°ë¡
            
        Returns:
            Graph: ë³€í™˜ëœ RDF ê·¸ëž˜í”„
        """
        graph = Graph()
        
        # ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ë°”ì¸ë”©
        graph.bind("", self.base_namespace)
        graph.bind("rdf", RDF_NS)
        graph.bind("rdfs", RDFS_NS)
        graph.bind("owl", OWL_NS)
        graph.bind("xsd", XSD_NS)
        
        # ì„­ì·¨ ê¸°ë¡ URI ìƒì„±
        consumption_uri = URIRef(f"{self.base_namespace}consumption_{hash(str(consumption.food_uri) + str(consumption.timestamp))}")
        
        # ì„­ì·¨ ê¸°ë¡ ì¸ìŠ¤í„´ìŠ¤
        graph.add((consumption_uri, RDF.type, self.base_namespace.FoodConsumption))
        graph.add((consumption_uri, self.base_namespace.consumedFood, consumption.food_uri))
        graph.add((consumption_uri, self.base_namespace.consumedAmount, Literal(consumption.amount_grams)))
        graph.add((consumption_uri, self.base_namespace.consumedCalories, Literal(consumption.calories_consumed)))
        graph.add((consumption_uri, self.base_namespace.consumedAt, Literal(consumption.timestamp)))
        
        return graph
    
    def convert_exercise_session_to_rdf(self, session: ExerciseSession) -> Graph:
        """
        ìš´ë™ ì„¸ì…˜ ë°ì´í„°ë¥¼ RDF ê·¸ëž˜í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            session: ìš´ë™ ì„¸ì…˜ ê¸°ë¡
            
        Returns:
            Graph: ë³€í™˜ëœ RDF ê·¸ëž˜í”„
        """
        graph = Graph()
        
        # ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ë°”ì¸ë”©
        graph.bind("", self.base_namespace)
        graph.bind("rdf", RDF_NS)
        graph.bind("rdfs", RDFS_NS)
        graph.bind("owl", OWL_NS)
        graph.bind("xsd", XSD_NS)
        
        # ìš´ë™ ì„¸ì…˜ URI ìƒì„±
        session_uri = URIRef(f"{self.base_namespace}session_{hash(str(session.exercise_uri) + str(session.timestamp))}")
        
        # ìš´ë™ ì„¸ì…˜ ì¸ìŠ¤í„´ìŠ¤
        graph.add((session_uri, RDF.type, self.base_namespace.ExerciseSession))
        graph.add((session_uri, self.base_namespace.performedExercise, session.exercise_uri))
        graph.add((session_uri, self.base_namespace.hasWeight, Literal(session.weight)))
        graph.add((session_uri, self.base_namespace.sessionDuration, Literal(session.duration)))
        graph.add((session_uri, self.base_namespace.caloriesBurned, Literal(session.calories_burned)))
        graph.add((session_uri, self.base_namespace.performedAt, Literal(session.timestamp)))
        
        return graph
    
    def merge_graphs(self, graphs: List[Graph]) -> Graph:
        """
        ì—¬ëŸ¬ RDF ê·¸ëž˜í”„ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
        
        Args:
            graphs: ë³‘í•©í•  ê·¸ëž˜í”„ ëª©ë¡
            
        Returns:
            Graph: ë³‘í•©ëœ ê·¸ëž˜í”„
        """
        if not graphs:
            return Graph()
        
        merged_graph = Graph()
        
        # ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ë°”ì¸ë”©
        merged_graph.bind("", self.base_namespace)
        merged_graph.bind("rdf", RDF_NS)
        merged_graph.bind("rdfs", RDFS_NS)
        merged_graph.bind("owl", OWL_NS)
        merged_graph.bind("xsd", XSD_NS)
        
        # ëª¨ë“  ê·¸ëž˜í”„ì˜ íŠ¸ë¦¬í”Œì„ ë³‘í•©
        total_triples = 0
        for graph in graphs:
            for triple in graph:
                merged_graph.add(triple)
                total_triples += 1
        
        print(f"âœ“ {len(graphs)}ê°œ ê·¸ëž˜í”„ ë³‘í•© ì™„ë£Œ: {total_triples}ê°œ íŠ¸ë¦¬í”Œ")
        return merged_graph
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì € í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            Dict[str, Any]: í†µê³„ ì •ë³´
        """
        return {
            "manager_statistics": self.stats.copy(),
            "configuration": {
                "base_namespace": str(self.base_namespace),
                "supported_formats": ["turtle", "xml", "n3", "nt"]
            },
            "timestamp": datetime.now().isoformat()
        }
    
    def reset_statistics(self) -> None:
        """í†µê³„ ì •ë³´ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.stats = {
            "loaded_files": 0,
            "merged_graphs": 0,
            "created_backups": 0,
            "validation_checks": 0
        }
        print("âœ“ ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì € í†µê³„ ì´ˆê¸°í™” ì™„ë£Œ")